{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.dataset.MI_dataset_all_subjects import MI_Dataset as MI_Dataset_all_subjects\n",
    "from src.dataset.MI_dataset_single_subject import MI_Dataset as MI_Dataset_single_subject\n",
    "\n",
    "from config.default import cfg\n",
    "\n",
    "\n",
    "from models.eegnet import EEGNet\n",
    "\n",
    "from utils.eval import accuracy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 1\n",
    "train_runs = [0,1,2,3,4]\n",
    "test_runs = [5]\n",
    "\n",
    "\n",
    "train_dataset = MI_Dataset_single_subject(subject, train_runs, device = device)\n",
    "test_dataset = MI_Dataset_single_subject(subject, test_runs, device = device)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,  batch_size=cfg['train']['batch_size'], shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset,  batch_size=cfg['train']['batch_size'], shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 240 samples\n",
      "Test dataset: 48 samples\n",
      "torch.Size([48, 22, 1001])\n",
      "tensor([3, 0, 2, 0, 3, 1, 1, 3, 2, 1, 3, 3, 0, 0, 0, 3, 3, 0, 3, 1, 3, 1, 3, 1,\n",
      "        2, 3, 2, 0, 3, 1, 1, 3, 0, 2, 2, 2, 0, 0, 3, 2, 3, 1, 1, 2, 1, 1, 2, 2],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset: {len(train_dataset)} samples\")\n",
    "print(f\"Test dataset: {len(test_dataset)} samples\")\n",
    "\n",
    "for features, label in train_dataloader:\n",
    "    print(features.shape)\n",
    "    print(label)\n",
    "    break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_block(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(conv_block,self).__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "                nn.Conv2d(1, 16, kernel_size=(1,64), bias=False,padding='same'),\n",
    "                nn.BatchNorm2d(16),\n",
    "                # problem,\n",
    "            )\n",
    "        self.depthwise = nn.Conv2d(16, 16, (22,1), stride=1, padding=0, dilation=1, groups=16, bias=False)\n",
    "        self.pointwise = nn.Conv2d(16, 16*2, 1, 1, 0, 1, 1, bias=False)\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.AvgPool2d(kernel_size=(1,8)),\n",
    "                nn.Conv2d(32, 32, kernel_size=(1,16), bias=False,padding='same'),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.ELU(),\n",
    "                nn.AvgPool2d(kernel_size=(1, 7)),\n",
    "                nn.Dropout(0.5),\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        out = self.conv_block_2(x)\n",
    "        # nn.utils.clip_grad_norm_(self.depthwise.parameters(), max_norm=1.0)  \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, num_classes: int = 4, channels: int = 22, samples: int = 1001,\n",
    "        dropout_rate: float = 0.5, kernel_length: int = 64, num_filters1: int = 16,\n",
    "        depth_multiplier: int = 2, num_filters2: int = 32, norm_rate: float = 0.25) -> None:\n",
    "        super(EEGNet, self).__init__()\n",
    "\n",
    "        self.channels = channels\n",
    "        self.samples = samples\n",
    "\n",
    "        # First convolutional block\n",
    "        # Temporal convolutional to learn frequency filters\n",
    "        self.conv1 = nn.Conv2d(1, num_filters1, (1, kernel_length), padding=(0, kernel_length // 2), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(num_filters1)\n",
    "        \n",
    "        # Depthwise convolutional block\n",
    "        # Connected to each feature map individually, to learn frequency-specific spatial filters\n",
    "        self.dw_conv1 = nn.Conv2d(num_filters1, num_filters1 * depth_multiplier, (channels, 1), groups=num_filters1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(num_filters1 * depth_multiplier)\n",
    "        self.activation = nn.ELU()\n",
    "        self.avg_pool1 = nn.AvgPool2d((1, 4))\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # Separable convolutional block\n",
    "        # Learns a temporal summary for each feature map individually, \n",
    "        # followed by a pointwise convolution, which learns how to optimally mix the feature maps together\n",
    "        self.sep_conv1 = nn.Conv2d(num_filters1 * depth_multiplier, num_filters1 * depth_multiplier, (1, 16), groups=num_filters1 * depth_multiplier, padding=(0, 8), bias=False)\n",
    "        self.conv2 = nn.Conv2d(num_filters1 * depth_multiplier, num_filters2, 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(num_filters2)\n",
    "        self.avg_pool2 = nn.AvgPool2d((1, 8))\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "\n",
    "       \n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.view(-1,  1, self.channels, self.samples)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.dw_conv1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.avg_pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.sep_conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.avg_pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, input_size = 32, num_heads=2):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        self.embed_dim = self.input_size    \n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        # Instantiate the PyTorch's built-in MultiheadAttention module with batch_first=True\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=self.embed_dim, num_heads=self.num_heads, dropout=0.5,  batch_first=True)\n",
    "        \n",
    "        # Output linear layer remains the same\n",
    "        self.W_O = nn.Linear(input_size, input_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # With batch_first=True, x is expected to be (batch_size, sequence_length, embedding_dim)\n",
    "        # We can pass x directly without transposing\n",
    "        x = x.permute(0,2,1)\n",
    "        #print('mha forward', x.shape)\n",
    "        attn_output, attn_output_weights = self.multihead_attn(x, x, x)\n",
    "        \n",
    "        # Since we are using batch_first=True, attn_output is already in the shape (batch_size, sequence_length, embedding_dim)\n",
    "        # So, no need to transpose it before passing through the final linear layer\n",
    "        output = self.W_O(attn_output)\n",
    "        output = self.dropout(output)\n",
    "        output = output.permute(0,2,1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation = 1):\n",
    "        super(CausalConv1d, self).__init__()\n",
    "        self.padding = (kernel_size - 1) * dilation\n",
    "        self.conv1d = nn.Conv1d(in_channels, out_channels, kernel_size, dilation=dilation)\n",
    "        nn.init.kaiming_uniform_(self.conv1d.weight, nonlinearity='linear')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.pad(x, (self.padding, 0))\n",
    "        return self.conv1d(x)\n",
    "    \n",
    "class TCN_block(nn.Module):\n",
    "    def __init__(self, depth=2):\n",
    "        super(TCN_block, self).__init__()\n",
    "        self.depth = depth\n",
    "\n",
    "\n",
    "        self.Activation_1 = nn.ELU()\n",
    "        self.TCN_Residual_1 = nn.Sequential(\n",
    "            #可能问题的所在\n",
    "            CausalConv1d(32, 32, 4, dilation=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            CausalConv1d(32, 32, 4, dilation=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "        \n",
    "        self.TCN_Residual = nn.ModuleList()\n",
    "        self.Activation = nn.ModuleList()\n",
    "        for i in range(depth-1):\n",
    "            TCN_Residual_n = nn.Sequential(\n",
    "            CausalConv1d(32, 32, 4, dilation=2**(i+1)),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            CausalConv1d(32, 32, 4, dilation=2**(i+1)),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "            self.TCN_Residual.append(TCN_Residual_n)\n",
    "            self.Activation.append(nn.ELU())   \n",
    "        \n",
    "    def forward(self, x):\n",
    "        block = self.TCN_Residual_1(x)\n",
    "        # print(block.shape)\n",
    "        block += x\n",
    "        block = self.Activation_1(block)\n",
    "        \n",
    "        for i in range(self.depth-1):\n",
    "            block_o = block\n",
    "            block = self.TCN_Residual[i](block)\n",
    "            block += block_o\n",
    "            # block = torch.add(block_o,block)\n",
    "            block = self.Activation[i](block)\n",
    "        return block[:, :, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ATCNet(nn.Module):\n",
    "    def __init__(self, num_classes = 4, fe = 'conv', fuze = 'average') -> None:\n",
    "        super(ATCNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        if fe == 'conv':\n",
    "            self.conv_block = conv_block()\n",
    "        if fe == 'eegnet':\n",
    "            self.conv_block = EEGNet()  \n",
    "\n",
    "        self.fuze = fuze# 'average' or 'concat'\n",
    "\n",
    "        self.attention_list = nn.ModuleList()\n",
    "        self.TCN_list = nn.ModuleList()\n",
    "        for i in range(5):\n",
    "            self.attention_list.append(MultiHeadAttention())\n",
    "            self.TCN_list.append(TCN_block())\n",
    "        \n",
    "        if self.fuze == 'average':\n",
    "            self.fuze_layers = nn.ModuleList()\n",
    "            for i in range(5):\n",
    "                self.fuze_layers.append(nn.Linear(32, num_classes))\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.flatten = nn.Flatten()\n",
    "        asd = 160 #2080 # 544\n",
    "        self.dense = nn.Linear(asd, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.unsqueeze(1)\n",
    "        block1 = self.conv_block(x) \n",
    "        #print(block1.shape) # [B,32,1,17]\n",
    "        n_windows = 5\n",
    "        block1 = block1.squeeze(2)\n",
    "\n",
    "\n",
    "        sliding_window_output = []\n",
    "        for i in range(n_windows):\n",
    "            start = i\n",
    "            end = block1.shape[2]-n_windows+i+1\n",
    "            block2 = block1[:,:, start:end]\n",
    "            #print(block2.shape) # [B,32,13]\n",
    "            block2 = self.attention_list[i](block2)\n",
    "            #sliding_window_output.append(block2)\n",
    "            #print(block2.shape)  # [B, 32, 13]\n",
    "            block2 = self.TCN_list[i](block2)\n",
    "            #print(block2.shape)   # [B, 32]\n",
    "            \n",
    "            sliding_window_output.append(block2)\n",
    "\n",
    "        if self.fuze == 'concat':\n",
    "            output = torch.cat(sliding_window_output, dim=1)\n",
    "            #print(output.shape) # [B, 32, 65]\n",
    "            #output = block1\n",
    "            output = self.flatten(output)\n",
    "            #print(output.shape)\n",
    "            output = self.dense(output)\n",
    "        if self.fuze == 'average':\n",
    "            for i in range(5):\n",
    "                sliding_window_output[i] = self.fuze_layers[i](sliding_window_output[i])\n",
    "            output = torch.stack(sliding_window_output, dim=2) # check dim may permute required\n",
    "            output = torch.mean(output, dim=2)\n",
    "            \n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2433, -0.2354,  0.3645, -0.0508]], device='cuda:0',\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = torch.randn(1, 22, 1001).to(device)\n",
    "model = ATCNet().to(device)\n",
    "model(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ATCNet().to(device)\n",
    "#summary(model, ( 22, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1788, -0.2459, -0.4350,  0.0487]], device='cuda:0',\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "out = model(dummy)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass\n",
    "model(next(iter(train_dataloader))[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Loss: 5.9273258447647095, Train accuracy: 44.17%, Test accuracy: 60.42%\n",
      "Epoch 20/200, Loss: 5.295874655246735, Train accuracy: 49.58%, Test accuracy: 45.83%\n",
      "Epoch 30/200, Loss: 4.981917023658752, Train accuracy: 51.67%, Test accuracy: 45.83%\n",
      "Epoch 40/200, Loss: 4.745257079601288, Train accuracy: 50.00%, Test accuracy: 54.17%\n",
      "Epoch 50/200, Loss: 4.471916615962982, Train accuracy: 59.58%, Test accuracy: 50.00%\n",
      "Epoch 60/200, Loss: 4.001338601112366, Train accuracy: 65.83%, Test accuracy: 54.17%\n",
      "Epoch 70/200, Loss: 3.6973262429237366, Train accuracy: 67.92%, Test accuracy: 41.67%\n",
      "Epoch 80/200, Loss: 3.550718069076538, Train accuracy: 70.83%, Test accuracy: 50.00%\n",
      "Epoch 90/200, Loss: 3.490455389022827, Train accuracy: 74.17%, Test accuracy: 47.92%\n",
      "Epoch 100/200, Loss: 2.7460367679595947, Train accuracy: 75.83%, Test accuracy: 45.83%\n",
      "Epoch 110/200, Loss: 2.9169896245002747, Train accuracy: 78.75%, Test accuracy: 50.00%\n",
      "Epoch 120/200, Loss: 3.3092034459114075, Train accuracy: 81.25%, Test accuracy: 56.25%\n",
      "Epoch 130/200, Loss: 2.4975138306617737, Train accuracy: 84.58%, Test accuracy: 52.08%\n",
      "Epoch 140/200, Loss: 2.4710568487644196, Train accuracy: 80.83%, Test accuracy: 45.83%\n",
      "Epoch 150/200, Loss: 2.5674001574516296, Train accuracy: 85.00%, Test accuracy: 54.17%\n",
      "Epoch 160/200, Loss: 2.5967592298984528, Train accuracy: 87.92%, Test accuracy: 56.25%\n",
      "Epoch 170/200, Loss: 2.734964519739151, Train accuracy: 82.50%, Test accuracy: 62.50%\n",
      "Epoch 180/200, Loss: 2.4697165489196777, Train accuracy: 85.42%, Test accuracy: 39.58%\n",
      "Epoch 190/200, Loss: 2.4684423208236694, Train accuracy: 85.00%, Test accuracy: 60.42%\n",
      "Epoch 200/200, Loss: 2.482538104057312, Train accuracy: 85.00%, Test accuracy: 54.17%\n",
      "##################################################\n",
      "Final_loss: 2.482538104057312\n",
      "Final train accuracy: 83.75%\n",
      "Final test accuracy: 52.08%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg['train']['learning_rate'], weight_decay=cfg['train']['weight_decay'])\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(cfg['train']['n_epochs']):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for batch_features, batch_labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_features)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    if epoch % 10 == 9:\n",
    "        train_accuracy = accuracy(model, train_dataloader)\n",
    "        test_accuracy = accuracy(model, test_dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/{cfg['train']['n_epochs']}, Loss: {epoch_loss}, Train accuracy: {train_accuracy:.2f}%, Test accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "print(\"#\"*50)\n",
    "print(f'Final_loss: {epoch_loss}')\n",
    "print(f'Final train accuracy: {accuracy(model, train_dataloader):.2f}%')\n",
    "print(f'Final test accuracy: {accuracy(model, test_dataloader):.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results:\n",
    "\n",
    "conv block 56%  \n",
    "\n",
    "conv + mha 56%\n",
    "\n",
    "conv + mha + tc concat (no dropout) 72% (max)\n",
    "\n",
    "conv + mha + tc concat = 54%   //  68% (max)\n",
    "\n",
    "conv + mha + tc concat = 58%   //  64% (max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
