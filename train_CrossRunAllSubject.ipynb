{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "from src.dataset.MI_dataset_single_subject import MI_Dataset as MI_Dataset_single_subject\n",
    "\n",
    "from config.default import cfg\n",
    "\n",
    "\n",
    "from models.conditioned_eegnet import ConditionedEEGNet\n",
    "\n",
    "from utils.eval import accuracy\n",
    "from utils.model import print_parameters, print_weights_statistics\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subjects = [1,2,3,4,5,6,7,8,9]\n",
    "subjects = [1]\n",
    "train_runs = {\n",
    "                1:[0, 1, 2, 3, 4],\n",
    "                2:[0, 1, 2, 3, 4],\n",
    "                3:[0, 1, 2, 3, 4],\n",
    "                4:[0, 1],\n",
    "                5:[0, 1, 2, 3, 4],\n",
    "                6:[0, 1, 2, 3, 4],\n",
    "                7:[0, 1, 2, 3, 4],\n",
    "                8:[0, 1, 2, 3, 4],\n",
    "                9:[0, 1, 2, 3, 4]\n",
    "        }\n",
    "test_runs = {\n",
    "                1:[5],\n",
    "                2:[5],\n",
    "                3:[5],\n",
    "                4:[2],\n",
    "                5:[5],\n",
    "                6:[5],\n",
    "                7:[5],\n",
    "                8:[5],\n",
    "                9:[5]\n",
    "}\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 240 samples\n"
     ]
    }
   ],
   "source": [
    "train_datasets = []\n",
    "\n",
    "for subject in subjects:\n",
    "    dataset = MI_Dataset_single_subject(subject, train_runs[subject], return_subject_id=True, device=device, verbose=False)\n",
    "    train_datasets.append(dataset)\n",
    "    channels = dataset.channels\n",
    "    time_steps = dataset.time_steps\n",
    "train_dataset = ConcatDataset(train_datasets)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "print(f\"Train dataset: {len(train_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset: 48 samples\n"
     ]
    }
   ],
   "source": [
    "test_datasets = []\n",
    "for subject in subjects:\n",
    "    test_datasets.append(MI_Dataset_single_subject(subject, test_runs[subject],return_subject_id=True, device=device, verbose=False))\n",
    "test_dataset = ConcatDataset(test_datasets)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(f\"Test dataset: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 240 samples\n",
      "Test dataset: 48 samples\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset: {len(train_dataset)} samples\")\n",
    "print(f\"Test dataset: {len(test_dataset)} samples\")\n",
    "\n",
    "for feature, label in train_dataloader:\n",
    "    # print(feature[0].shape)\n",
    "    # print(feature[1].shape)\n",
    "    # print(label)\n",
    "    print(feature[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eeg_processor.conv1.weight.... --> 1024\n",
      "eeg_processor.bn1.weight...... --> 16\n",
      "eeg_processor.bn1.bias........ --> 16\n",
      "eeg_processor.dw_conv1.weight. --> 704\n",
      "eeg_processor.bn2.weight...... --> 32\n",
      "eeg_processor.bn2.bias........ --> 32\n",
      "eeg_processor.sep_conv1.weight --> 512\n",
      "eeg_processor.conv2.weight.... --> 1024\n",
      "eeg_processor.bn3.weight...... --> 32\n",
      "eeg_processor.bn3.bias........ --> 32\n",
      "subject_processor.fn1.weight.. --> 16\n",
      "subject_processor.fn1.bias.... --> 16\n",
      "subject_norm.weight........... --> 16\n",
      "subject_norm.bias............. --> 16\n",
      "eeg_norm.weight............... --> 384\n",
      "eeg_norm.bias................. --> 384\n",
      "attn_norm.weight.............. --> 32\n",
      "attn_norm.bias................ --> 32\n",
      "query.weight.................. --> 12288\n",
      "key.weight.................... --> 512\n",
      "value.weight.................. --> 12288\n",
      "fn1.weight.................... --> 4096\n",
      "fn1.bias...................... --> 128\n",
      "fn2.weight.................... --> 512\n",
      "fn2.bias...................... --> 4\n",
      "eeg_fn.weight................. --> 12288\n",
      "eeg_fn.bias................... --> 32\n",
      "\n",
      "Total Parameter Count:........ --> 46468\n"
     ]
    }
   ],
   "source": [
    "model = ConditionedEEGNet(num_subjects = len(subjects), channels = channels, samples= time_steps, num_classes = 4)\n",
    "model.to(device)\n",
    "print_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eeg_processor.calculate_output_dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Loss: 4.016072154045105, Train accuracy: 56.67%, Test accuracy: 37.50%\n",
      "Epoch 20/200, Loss: 3.026186525821686, Train accuracy: 73.75%, Test accuracy: 60.42%\n",
      "Epoch 30/200, Loss: 2.08597269654274, Train accuracy: 83.33%, Test accuracy: 52.08%\n",
      "Epoch 40/200, Loss: 1.3158859610557556, Train accuracy: 93.33%, Test accuracy: 60.42%\n",
      "Epoch 50/200, Loss: 0.7591616064310074, Train accuracy: 97.08%, Test accuracy: 56.25%\n",
      "Epoch 60/200, Loss: 0.4863005429506302, Train accuracy: 99.17%, Test accuracy: 56.25%\n",
      "Epoch 70/200, Loss: 0.3308986648917198, Train accuracy: 99.17%, Test accuracy: 54.17%\n",
      "Epoch 80/200, Loss: 0.2314380593597889, Train accuracy: 100.00%, Test accuracy: 64.58%\n",
      "Epoch 90/200, Loss: 0.3130871243774891, Train accuracy: 98.33%, Test accuracy: 54.17%\n",
      "Epoch 100/200, Loss: 0.25403326377272606, Train accuracy: 99.58%, Test accuracy: 56.25%\n",
      "Epoch 110/200, Loss: 0.1880739890038967, Train accuracy: 99.58%, Test accuracy: 47.92%\n",
      "Epoch 120/200, Loss: 0.16927574574947357, Train accuracy: 99.58%, Test accuracy: 56.25%\n",
      "Epoch 130/200, Loss: 0.19930939748883247, Train accuracy: 99.17%, Test accuracy: 56.25%\n",
      "Epoch 140/200, Loss: 0.15217071026563644, Train accuracy: 100.00%, Test accuracy: 52.08%\n",
      "Epoch 150/200, Loss: 0.20168403163552284, Train accuracy: 100.00%, Test accuracy: 60.42%\n",
      "Epoch 160/200, Loss: 0.1813022345304489, Train accuracy: 100.00%, Test accuracy: 60.42%\n",
      "Epoch 170/200, Loss: 0.21145373582839966, Train accuracy: 99.58%, Test accuracy: 58.33%\n",
      "Epoch 180/200, Loss: 0.18104523047804832, Train accuracy: 100.00%, Test accuracy: 54.17%\n",
      "Epoch 190/200, Loss: 0.18282733485102654, Train accuracy: 100.00%, Test accuracy: 66.67%\n",
      "Epoch 200/200, Loss: 0.21844645962119102, Train accuracy: 100.00%, Test accuracy: 68.75%\n",
      "##################################################\n",
      "Final_loss: 0.21844645962119102\n",
      "Final train accuracy: 100.00%\n",
      "Final test accuracy: 60.42%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg['train']['learning_rate'], weight_decay=cfg['train']['weight_decay'])\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(cfg['train']['n_epochs']):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for batch_features, batch_labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_features[0], batch_features[1])\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    if epoch % 10 == 9:\n",
    "        train_accuracy = accuracy(model, train_dataloader)\n",
    "        test_accuracy = accuracy(model, test_dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/{cfg['train']['n_epochs']}, Loss: {epoch_loss}, Train accuracy: {train_accuracy:.2f}%, Test accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "print(\"#\"*50)\n",
    "print(f'Final_loss: {epoch_loss}')\n",
    "print(f'Final train accuracy: {accuracy(model, train_dataloader):.2f}%')\n",
    "print(f'Final test accuracy: {accuracy(model, test_dataloader):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
