{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "from src.dataset.MI_dataset_single_subject import MI_Dataset as MI_Dataset_single_subject\n",
    "\n",
    "from config.default import cfg\n",
    "\n",
    "\n",
    "from models.eegnet import EEGNet\n",
    "\n",
    "from utils.eval import accuracy\n",
    "from utils.model import print_parameters, print_weights_statistics\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 2016 samples\n"
     ]
    }
   ],
   "source": [
    "train_datasets = []\n",
    "\n",
    "for subject in cfg['data']['subjects']:\n",
    "    dataset = MI_Dataset_single_subject(subject, cfg['data']['train_runs'][subject], return_subject_id=False, device=device, verbose=False)\n",
    "    train_datasets.append(dataset)\n",
    "    channels = dataset.channels\n",
    "    time_steps = dataset.time_steps\n",
    "train_dataset = ConcatDataset(train_datasets)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=cfg['train']['batch_size'], shuffle=True)\n",
    "print(f\"Train dataset: {len(train_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset: 432 samples\n"
     ]
    }
   ],
   "source": [
    "test_datasets = []\n",
    "for subject in cfg['data']['subjects']:\n",
    "    test_datasets.append(MI_Dataset_single_subject(subject, cfg['data']['test_runs'][subject],return_subject_id=False, device=device, verbose=False))\n",
    "test_dataset = ConcatDataset(test_datasets)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=cfg['train']['batch_size'], shuffle=False)\n",
    "print(f\"Test dataset: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 2016 samples\n",
      "Test dataset: 432 samples\n",
      "torch.Size([22, 401])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset: {len(train_dataset)} samples\")\n",
    "print(f\"Test dataset: {len(test_dataset)} samples\")\n",
    "\n",
    "for feature, label in train_dataloader:\n",
    "    print(feature[0].shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight.... --> 1024\n",
      "bn1.weight...... --> 16\n",
      "bn1.bias........ --> 16\n",
      "dw_conv1.weight. --> 704\n",
      "bn2.weight...... --> 32\n",
      "bn2.bias........ --> 32\n",
      "sep_conv1.weight --> 512\n",
      "conv2.weight.... --> 1024\n",
      "bn3.weight...... --> 32\n",
      "bn3.bias........ --> 32\n",
      "dense.weight.... --> 1536\n",
      "dense.bias...... --> 4\n",
      "\n",
      "Total Parameter Count: --> 4964\n"
     ]
    }
   ],
   "source": [
    "model = EEGNet(channels = channels, samples= time_steps, num_classes = 4)\n",
    "model.to(device)\n",
    "print_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Loss: 38.20961391925812, Train accuracy: 46.92%, Test accuracy: 39.12%\n",
      "Epoch 20/200, Loss: 36.29228055477142, Train accuracy: 50.00%, Test accuracy: 43.52%\n",
      "Epoch 30/200, Loss: 35.50695067644119, Train accuracy: 52.48%, Test accuracy: 44.68%\n",
      "Epoch 40/200, Loss: 34.626114308834076, Train accuracy: 53.32%, Test accuracy: 45.37%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg['train']['learning_rate'], weight_decay=cfg['train']['weight_decay'])\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(cfg['train']['n_epochs']):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for batch_features, batch_labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        if isinstance(batch_features, list):\n",
    "            outputs = model(*batch_features)\n",
    "        else:\n",
    "            outputs = model(batch_features)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    if epoch % 10 == 9:\n",
    "        train_accuracy = accuracy(model, train_dataloader)\n",
    "        test_accuracy = accuracy(model, test_dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/{cfg['train']['n_epochs']}, Loss: {epoch_loss}, Train accuracy: {train_accuracy:.2f}%, Test accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "print(\"#\"*50)\n",
    "print(f'Final_loss: {epoch_loss}')\n",
    "print(f'Final train accuracy: {accuracy(model, train_dataloader):.2f}%')\n",
    "print(f'Final test accuracy: {accuracy(model, test_dataloader):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
